# -*- coding: utf-8 -*-
"""VIT-Google-Skyrmiones.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S5wclWn4SyH8g_w7eM5S4apv2zS62eH7
"""

#!pip install transformers torch torchvision

import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader,random_split
import torch.nn.functional as F
from transformers import ViTFeatureExtractor, ViTForImageClassification
from torch.optim import AdamW # Import AdamW from torch.optim
from torch.utils.data import Dataset, DataLoader,ConcatDataset
import os
from tqdm.auto import tqdm
import zipfile
from PIL import Image
from io import BytesIO
from sklearn.metrics import classification_report,confusion_matrix
import seaborn as sns

from itertools import chain
import math
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
from datetime import datetime
import json

# Función "collate" personalizada que utiliza el feature extractor
model2_repo_id = 'google/vit-base-patch16-224-in21k'
model2_feature_extractor = ViTFeatureExtractor.from_pretrained(model2_repo_id)

# Definir la transformación para las imágenes
rgb_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=3),  # Convertir imágenes de escala de grises a 3 canales (RGB)                 # Redimensionar al tamaño requerido por ViT
])

def model2_collate_fn(batch):
    # Separa las imágenes y etiquetas
    images, labels = zip(*batch)
    # Aplica el feature extractor a la lista de imágenes (se espera que sean objetos PIL.Image)
    inputs = model2_feature_extractor(list(images), return_tensors="pt")
    inputs["labels"] = torch.tensor(labels)
    return inputs

# Ruta principal
dataset_data_dir = "/home/mitchellmirano/Desktop/MitchellProjects/H vs J phase diagram/DATASET"

# Cargar dataset completo
full_dataset = ImageFolder(root=dataset_data_dir, transform=rgb_transform)

# Definir proporción train/test (ej. 80/20)
train_size = int(0.8 * len(full_dataset))
test_size  = len(full_dataset) - train_size

train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])

# Crear DataLoader
batch_size = 8

model2_train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=model2_collate_fn)
model2_test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=model2_collate_fn)

len(train_dataset),len(test_dataset),len(train_dataset) + len(test_dataset)

# Actualizar mapeos de etiquetas
num_classes = len(train_dataset.dataset.classes)
id2label = {i: c for i, c in enumerate(train_dataset.dataset.classes)}
label2id = {c: i for i, c in enumerate(train_dataset.dataset.classes)}

with open('classes/id2label_vit.json', 'w') as f:
    json.dump(id2label, f)

with open('classes/label2id_vit.json', 'w') as f:
    json.dump(label2id, f)

# Cargar el modelo ViT
model = ViTForImageClassification.from_pretrained(
    model2_repo_id,
    num_labels=num_classes,
    id2label=id2label,
    label2id=label2id
)



# Configurar el dispositivo (GPU si está disponible)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

print("Test batch")
for batch in model2_train_loader:
    model_inputs = {k: v.to(device) for k, v in batch.items()}
    outputs = model(**model_inputs)
    print(outputs)
    break

# Definir optimizador y función de pérdida
optimizer = AdamW(model.parameters(), lr=1e-5)
criterion = nn.CrossEntropyLoss()

import math
train_iters = math.ceil(len(train_dataset)/batch_size)
test_iters =  math.ceil(len(test_dataset)/batch_size)

print(f'Train iters: {train_iters}')
print(f'Test iters: {test_iters}')


# Función para entrenar una época
def train_epoch(model, model2_dataloader, optimizer, criterion, device):
    model.train()
    running_loss = 0.0
    pbar = tqdm(model2_dataloader, desc="Entrenamiento", total=train_iters, leave=False)
    for model2_batch in pbar:

        model2_inputs = {k: v.to(device) for k, v in model2_batch.items()}
        optimizer.zero_grad()
        outputs = model(**model2_inputs)
        loss = criterion(outputs.logits, model2_inputs["labels"])
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * model2_inputs["labels"].size(0)
        pbar.set_postfix({"loss": loss.item()})

    epoch_loss = running_loss / len(model2_dataloader.dataset)
    return epoch_loss

# Función para evaluar el modelo en el conjunto de test
def evaluate(model, model2_dataloader, device):
    model.eval()
    correct, total = 0, 0
    with torch.no_grad():
        pbar = tqdm( model2_dataloader, desc="Evaluación", total=test_iters, leave=False)
        for model2_batch in pbar:

            model2_inputs = {k: v.to(device) for k, v in model2_batch.items()}
            outputs = model(**model2_inputs)
            predictions = torch.argmax(outputs.logits, dim=-1)
            labels = model2_inputs["labels"]
            correct += (predictions == labels).sum().item()
            total += labels.size(0)
    accuracy = correct / total if total > 0 else 0
    return accuracy

# Función completa de entrenamiento
def train_model(model,
                model2_train_loader,
                model2_test_loader,
                optimizer, criterion, device, epochs=5):
    for epoch in range(epochs):
        train_loss = train_epoch(model,model2_train_loader, optimizer, criterion, device)
        accuracy = evaluate(model,  model2_test_loader, device)

        print(f"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Accuracy: {accuracy*100:.2f}%")

        if accuracy > 0.98:
            break

# Entrenar el modelo (ajusta el número de épocas si lo deseas)
start = datetime.now()
train_model(model,
            model2_train_loader,
            model2_test_loader, optimizer, criterion, device, epochs=4)
end = datetime.now()
delta = end - start
print(f"Training time: {delta.total_seconds()/60:.3f}")

model.eval()

all_preds, all_labels = [], []
all_probs = []

start = datetime.now()

with torch.no_grad():
    pbar = tqdm( model2_test_loader, desc="Evaluación", total=len(model2_test_loader), leave=False)
    for model2_batch in pbar:
        model2_inputs = {k: v.to(device) for k, v in model2_batch.items()}

        # Obtener las salidas del modelo
        outputs = model(**model2_inputs)

        # Calcular las probabilidades usando softmax
        probabilities = F.softmax(outputs.logits, dim=1)

        # Obtener las predicciones
        predictions = torch.argmax(outputs.logits, dim=-1)

        # Extraer las etiquetas verdaderas
        labels = model2_inputs["labels"]

        # Guardar las predicciones, etiquetas y probabilidades
        all_preds.extend(predictions.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_probs.extend(probabilities.cpu().numpy()[:, 1])

end = datetime.now()
delta = end - start
print(f"Inference time: {delta.total_seconds()/60:.3f} minutes")

class_report = classification_report(all_labels, all_preds, target_names=train_dataset.dataset.classes,digits=3)

with open('results/SkyrmionClassifierViT.txt', 'w') as f:
    f.write(class_report)
print(class_report)

conf_matrix = confusion_matrix(all_labels, all_preds)
sns.heatmap(conf_matrix, annot=True, fmt='d',
            cmap='Blues',
            xticklabels=train_dataset.dataset.classes,
            yticklabels=train_dataset.dataset.classes)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.savefig('results/SkyrmionClassifierViT.png')

torch.save(model,'models/SkyrmionClassifierViT')